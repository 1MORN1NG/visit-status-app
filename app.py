import streamlit as st
import pandas as pd
import io
import zipfile
import re
import itertools
import os
from datetime import datetime

st.title("üìä ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ (Visit + Leave + Sell In)")

# ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
mode = st.radio("üìå ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", [
    "‡∏£‡∏ß‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Visit",
    "‡∏£‡∏ß‡∏° Visit + ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô",
    "‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Sell In Total (Excel)"
])

# ‡πÇ‡∏´‡∏°‡∏î: ‡∏£‡∏ß‡∏° Visit ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
if mode == "‡∏£‡∏ß‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Visit":
    st.markdown("### üîÅ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Visit Master ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏£‡∏ß‡∏°‡πÑ‡∏ß‡πâ")
    previous_file = st.file_uploader("üì• visit_merged.csv", type=["csv"])
    visit_files = st.file_uploader("1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Visit (.csv) ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°", type=["csv"], accept_multiple_files=True)

    if visit_files:
        if st.button("üîÅ ‡∏£‡∏ß‡∏° Visit ‡πÉ‡∏´‡∏°‡πà"):
            with st.spinner("üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                visit_columns = [
                    "Id", "Number", "DATE", "UserName", "FirstName", "CustomerCOde", "Customer_Name",
                    "Customer_Location", "survey_updated_at", "‡πÄ‡∏ä‡πá‡∏Ñ‡∏≠‡∏¥‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô (‡πÄ‡∏ã‡∏•‡∏ü‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô)",
                    "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏£‡πâ‡∏≤‡∏ô", "‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤",
                    "‡∏Å‡∏£‡∏ì‡∏µ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á", "‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏≠‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô (‡πÄ‡∏ã‡∏•‡∏ü‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô)"
                ]

                all_visit_data = pd.DataFrame()
                for upload in visit_files:
                    filename = upload.name
                    df = pd.read_csv(upload, skiprows=2, usecols=range(15), encoding='utf-8-sig')
                    df.columns = visit_columns
                    df["source_file"] = filename

                    match = re.search(r'wk(\d{1,2})', filename.lower())
                    week_num = int(match.group(1)) if match else None
                    df["week"] = week_num

                    all_visit_data = pd.concat([all_visit_data, df], ignore_index=True)

                all_visit_data = all_visit_data.rename(columns={"CustomerCOde": "Customer_COde"})

                if previous_file:
                    previous = pd.read_csv(previous_file, encoding='utf-8-sig')
                    previous = previous.rename(columns={"CustomerCOde": "Customer_COde"})
                else:
                    previous = pd.DataFrame()

                visit_data = pd.concat([previous, all_visit_data], ignore_index=True).drop_duplicates()

                timestamp = datetime.now().strftime("%Y-%m-%d")
                filename = f"visit_merged_{timestamp}.csv"

                buffer = io.BytesIO()
                visit_data.to_csv(buffer, index=False, encoding="utf-8-sig")
                buffer.seek(0)

                st.success("‚úÖ ‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Visit ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                st.download_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Visit ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", data=buffer, file_name=filename)

# ‡πÇ‡∏´‡∏°‡∏î:‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô
if mode == "‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô":
    visit_file = st.file_uploader("üì• visit_merged.csv (‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß)", type=["csv"])
    master_file = st.file_uploader("üì• Master.xlsx", type=["xlsx"])
    leave_file = st.file_uploader("üì• Leave.xlsx", type=["xlsx"])

    if visit_file and master_file and leave_file:
        if st.button("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô"):
            with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                visit_data = pd.read_csv(visit_file, encoding='utf-8-sig')
                visit_data = visit_data.rename(columns={"CustomerCOde": "Customer_COde"})

                master_bkk = pd.read_excel(master_file, sheet_name="BKK")
                master_cnx = pd.read_excel(master_file, sheet_name="CNX")
                master_df = pd.concat([master_bkk, master_cnx], ignore_index=True)

                week_ref_preview = pd.read_excel(master_file, sheet_name="Week")
                week_ref = week_ref_preview[1:].copy()
                week_ref.columns = ["Year", "week", "Start_Date", "End_Date", "Monthnum", "Month", "Index"]
                week_ref["Start_Date"] = pd.to_datetime(week_ref["Start_Date"])
                week_ref["End_Date"] = pd.to_datetime(week_ref["End_Date"])
                week_ref["week"] = week_ref["week"].astype(int)

                leave_data = pd.read_excel(leave_file)
                leave_data = leave_data.rename(columns={"user": "User"})
                leave_data["Date"] = pd.to_datetime(leave_data["Date"], errors='coerce')

                def map_week_from_date(date):
                    matched = week_ref[(week_ref["Start_Date"] <= date) & (week_ref["End_Date"] >= date)]
                    if not matched.empty:
                        return int(matched["week"].values[0])
                    return None

                leave_data["mapped_week"] = leave_data["Date"].apply(map_week_from_date)

                user_to_store = master_df[["USER DE", "StoreCode1"]].dropna()
                user_to_store.columns = ["User", "Customer_COde"]
                leave_data = leave_data.merge(user_to_store, on="User", how="left")

                store_list = visit_data["Customer_COde"].dropna().unique()
                week_list = sorted(visit_data["week"].dropna().unique())
                base = pd.DataFrame(itertools.product(store_list, week_list), columns=["Customer_COde", "week"])

                visit_flag = visit_data[["Customer_COde", "week", "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤"]].drop_duplicates()
                visit_flag = visit_flag.rename(columns={"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤": "has_visit"})
                base = base.merge(visit_flag, on=["Customer_COde", "week"], how="left")

                leave_flag = leave_data[["Customer_COde", "mapped_week", "‡∏Å‡∏≤‡∏£‡∏•‡∏≤"]].drop_duplicates()
                leave_flag = leave_flag.rename(columns={"mapped_week": "week"})
                base = base.merge(leave_flag, on=["Customer_COde", "week"], how="left")

                base_sorted = base.sort_values(by=["Customer_COde", "week"])

                def flag_cancel(row):
                    return "‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£" if row["has_visit"] == "‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£" else None

                base_sorted["cancel_flag"] = base_sorted.apply(flag_cancel, axis=1)

                def carry_cancel(df):
                    df = df.sort_values(by="week")
                    df["cancel_carried"] = df["cancel_flag"].eq("‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£").cummax().replace({False: None, True: "‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£"})
                    return df

                base_sorted = base_sorted.groupby("Customer_COde").apply(carry_cancel).reset_index(drop=True)

                def determine_status(row):
                    if row["has_visit"] == "‡∏£‡πâ‡∏≤‡∏ô‡πÄ‡∏õ‡∏¥‡∏î":
                        return "‡∏£‡πâ‡∏≤‡∏ô‡πÄ‡∏õ‡∏¥‡∏î"
                    elif row["cancel_carried"] == "‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£":
                        return "‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£"
                    elif pd.notna(row["‡∏Å‡∏≤‡∏£‡∏•‡∏≤"]):
                        return row["‡∏Å‡∏≤‡∏£‡∏•‡∏≤"]
                    else:
                        return "‡∏Ç‡∏≤‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°"

                base_unique = base_sorted.drop_duplicates(subset=["Customer_COde", "week"])
                base_unique["status"] = base_unique.apply(determine_status, axis=1)

                pivot_df = base_unique.pivot(index="Customer_COde", columns="week", values="status")
                pivot_df.columns = [f"WK{int(c)}" for c in pivot_df.columns]
                pivot_df.reset_index(inplace=True)

                buffer = io.BytesIO()
                timestamp = datetime.now().strftime("%Y-%m-%d")
                pivot_df.to_csv(buffer, index=False, encoding="utf-8-sig")
                buffer.seek(0)

                filename = f"status_summary_{timestamp}.csv"
                st.success("‚úÖ ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡πâ‡∏≤‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!")
                st.download_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î status_summary.csv", data=buffer, file_name=filename)

# ‡πÇ‡∏´‡∏°‡∏î: ‡∏£‡∏ß‡∏° Sell In
if mode == "‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå Sell In Total (Excel)":
    st.markdown("### üîÅ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Sell In Master ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏£‡∏ß‡∏°‡πÑ‡∏ß‡πâ")
    sellin_master_file = st.file_uploader("üì• sellin_total_master.xlsx", type=["xlsx"])

    sellin_files = st.file_uploader("üì¶ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Sell In (.xlsx) ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°", type=["xlsx"], accept_multiple_files=True)

    if sellin_files and st.button("üîÅ ‡∏£‡∏ß‡∏° Sell In"):
        with st.spinner("üßæ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
            all_sheets = pd.DataFrame()

            if sellin_master_file:
                df_master = pd.read_excel(sellin_master_file)
                all_sheets = pd.concat([all_sheets, df_master], ignore_index=True)

            for f in sellin_files:
                df = pd.read_excel(f)
                all_sheets = pd.concat([all_sheets, df], ignore_index=True)

            buffer = io.BytesIO()
            all_sheets.to_excel(buffer, index=False, engine='xlsxwriter')
            buffer.seek(0)

            timestamp = datetime.now().strftime("%Y-%m-%d")
            filename = f"sell_in_total_{timestamp}.xlsx"

            st.success("‚úÖ ‡∏£‡∏ß‡∏° Sell In ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
            st.download_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Sell In ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", data=buffer, file_name=filename)
